{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a27188a7",
   "metadata": {},
   "source": [
    "# 1. Header Tags from wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "372fa4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Header Tag\n",
       "0           Welcome to Wikipedia\n",
       "1  From today's featured article\n",
       "2               Did you know ...\n",
       "3                    In the news\n",
       "4                    On this day\n",
       "5       Today's featured picture\n",
       "6       Other areas of Wikipedia\n",
       "7    Wikipedia's sister projects\n",
       "8            Wikipedia languages"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the required libraries for scraping data\n",
    "from bs4 import BeautifulSoup   #It will parse the source code and get required data\n",
    "import requests                 #It will send request to the to get source code\n",
    "import pandas as pd             # It will help to make dataframe\n",
    "\n",
    "#Requesting the url to get source code\n",
    "wikipedia = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "\n",
    "# Getting the contents of webpage\n",
    "wikicontent = BeautifulSoup(wikipedia.content)\n",
    "\n",
    "headerlist = []    # Creating an empty list to store all the tags in it\n",
    "\n",
    "#We will use for loop to extract all the tags one by one\n",
    "for i in wikicontent.find_all('span',class_=\"mw-headline\"):\n",
    "    headerlist.append(i.text)     # Appending all the header tags one by one in list\n",
    "    \n",
    "    \n",
    "# Making dataframe\n",
    "framing = pd.DataFrame({'Header Tag':headerlist})\n",
    "framing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276edd79",
   "metadata": {},
   "source": [
    "# 2. Top Rated 100 IMDB Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc5b05c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[The, Shawshank, Redemption]</td>\n",
       "      <td>[9.3]</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, Godfather]</td>\n",
       "      <td>[9.2]</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, Godfather, Part, II]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The, Dark, Knight]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[12, Angry, Men]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[North, by, Northwest]</td>\n",
       "      <td>[8.3]</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[A, Clockwork, Orange]</td>\n",
       "      <td>[8.3]</td>\n",
       "      <td>(1971)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[Snatch]</td>\n",
       "      <td>[8.2]</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[Le, fabuleux, destin, d'Amélie, Poulain]</td>\n",
       "      <td>[8.3]</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[The, Kid]</td>\n",
       "      <td>[8.3]</td>\n",
       "      <td>(1921)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Movie Name Rating Year of Release\n",
       "0                [The, Shawshank, Redemption]  [9.3]          (1994)\n",
       "1                            [The, Godfather]  [9.2]          (1972)\n",
       "2                  [The, Godfather, Part, II]    [9]          (1974)\n",
       "3                         [The, Dark, Knight]    [9]          (2008)\n",
       "4                            [12, Angry, Men]    [9]          (1957)\n",
       "..                                        ...    ...             ...\n",
       "95                     [North, by, Northwest]  [8.3]          (1959)\n",
       "96                     [A, Clockwork, Orange]  [8.3]          (1971)\n",
       "97                                   [Snatch]  [8.2]          (2000)\n",
       "98  [Le, fabuleux, destin, d'Amélie, Poulain]  [8.3]          (2001)\n",
       "99                                 [The, Kid]  [8.3]          (1921)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting all the required libraries\n",
    "from bs4 import BeautifulSoup  # This will help to get the required data\n",
    "import requests # This will send request to the url for source code\n",
    "import pandas as pd\n",
    "\n",
    "# Sending request to the url\n",
    "re = requests.get('https://www.imdb.com/list/ls091520106/?sort=list_order,asc&st_dt=&mode=simple&page=1&ref_=ttls_vw_smp')\n",
    "\n",
    "# Getting the contents of the page\n",
    "bs = BeautifulSoup(re.content)\n",
    "\n",
    "ml = [] # Creating an empty list to store movies \n",
    "for i in bs.find_all('span',class_='lister-item-header'): # Getting movies name one by one\n",
    "    ml.append(i.text.split()[1:-1])  # Appending them in list by splitting the undesired data\n",
    "    \n",
    "rt = [] # Creating list to store raitngs given to the movies\n",
    "for i in bs.find_all('div',class_='col-imdb-rating'): # Finding ratings of the movies respectively one by one\n",
    "    rt.append(i.text.split())  # Appending the ratings of the movies in list by splitting undesired data one by one\n",
    "    \n",
    "yor = [] # List to store year of release\n",
    "for i in bs.find_all('span',class_='lister-item-year text-muted unbold'): # Getting year of release one by one respectively\n",
    "    yor.append(i.text) # Appending one by one in list\n",
    "    \n",
    "# Making dataframe\n",
    "df = pd.DataFrame({'Movie Name':ml,'Rating':rt,'Year of Release':yor})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e2fcd2",
   "metadata": {},
   "source": [
    "# 3. Top 100 Indian Movies of IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6765331b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Golmaal]</td>\n",
       "      <td>[8.5]</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3, Idiots]</td>\n",
       "      <td>[8.4]</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Taare, Zameen, Par]</td>\n",
       "      <td>[8.4]</td>\n",
       "      <td>(2007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Black, Friday]</td>\n",
       "      <td>[8.4]</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Guide]</td>\n",
       "      <td>[8.4]</td>\n",
       "      <td>(1965)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[Rangeela]</td>\n",
       "      <td>[7.4]</td>\n",
       "      <td>(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[Jaane, Tu..., Ya, Jaane, Na]</td>\n",
       "      <td>[7.4]</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[Socha, Na, Tha]</td>\n",
       "      <td>[7.4]</td>\n",
       "      <td>(2005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[Qayamat, Se, Qayamat, Tak]</td>\n",
       "      <td>[7.4]</td>\n",
       "      <td>(1988)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[Gunda]</td>\n",
       "      <td>[7.4]</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Movie Name Rating Year of Release\n",
       "0                       [Golmaal]  [8.5]          (1979)\n",
       "1                     [3, Idiots]  [8.4]          (2009)\n",
       "2            [Taare, Zameen, Par]  [8.4]          (2007)\n",
       "3                 [Black, Friday]  [8.4]          (2004)\n",
       "4                         [Guide]  [8.4]          (1965)\n",
       "..                            ...    ...             ...\n",
       "95                     [Rangeela]  [7.4]          (1995)\n",
       "96  [Jaane, Tu..., Ya, Jaane, Na]  [7.4]          (2008)\n",
       "97               [Socha, Na, Tha]  [7.4]          (2005)\n",
       "98    [Qayamat, Se, Qayamat, Tak]  [7.4]          (1988)\n",
       "99                        [Gunda]  [7.4]          (1998)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "from bs4 import BeautifulSoup # This will help to get content\n",
    "import requests  # This will send request to the server for source code\n",
    "import pandas as pd  # This will help to make dataframe\n",
    "\n",
    "# Sending the request to the server\n",
    "re = requests.get('https://www.imdb.com/list/ls009997493/?sort=user_rating,desc&st_dt=&mode=simple&page=1&ref_=ttls_vw_smp')\n",
    "\n",
    "# Getting the page contents\n",
    "bs = BeautifulSoup(re.content)\n",
    "\n",
    "# Making list to store Movies\n",
    "ml = []\n",
    "for i in bs.find_all('span',class_='lister-item-header'): # Getting the required data\n",
    "    ml.append(i.text.split()[1:-1]) # Appending only required data into the list\n",
    "    \n",
    "# Making list to store their ratings repectively\n",
    "rt = []\n",
    "for i in bs.find_all('div',class_='col-imdb-rating'): # Getting the ratings of the movies respectively one by one\n",
    "    rt.append(i.text.split())  # Appending only required datas into the list by splitting them\n",
    "    \n",
    "# Making list to store Year of release of the movies one by one\n",
    "yor = []\n",
    "for i in bs.find_all('span',class_='lister-item-year text-muted unbold'): # Getting year of release from the page respectively\n",
    "    yor.append(i.text)  # Appending the data into the list one by one respectively\n",
    "    \n",
    "# Making dataframe\n",
    "df = pd.DataFrame({'Movie Name':ml,'Rating':rt,'Year of Release':yor})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f199ab",
   "metadata": {},
   "source": [
    "# 4. Former Presidents List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "36ceb785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Former Presidents Name</th>\n",
       "      <th>Terms of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Former Presidents Name  \\\n",
       "0           Shri Ram Nath Kovind    \n",
       "1          Shri Pranab Mukherjee    \n",
       "2   Smt Pratibha Devisingh Patil    \n",
       "3         DR. A.P.J. Abdul Kalam    \n",
       "4           Shri K. R. Narayanan    \n",
       "5        Dr Shankar Dayal Sharma    \n",
       "6            Shri R Venkataraman    \n",
       "7               Giani Zail Singh    \n",
       "8      Shri Neelam Sanjiva Reddy    \n",
       "9       Dr. Fakhruddin Ali Ahmed    \n",
       "10  Shri Varahagiri Venkata Giri    \n",
       "11              Dr. Zakir Husain    \n",
       "12  Dr. Sarvepalli Radhakrishnan    \n",
       "13           Dr. Rajendra Prasad    \n",
       "\n",
       "                                      Terms of Office  \n",
       "0                     25 July, 2017 to 25 July, 2022   \n",
       "1                     25 July, 2012 to 25 July, 2017   \n",
       "2                     25 July, 2007 to 25 July, 2012   \n",
       "3                     25 July, 2002 to 25 July, 2007   \n",
       "4                     25 July, 1997 to 25 July, 2002   \n",
       "5                     25 July, 1992 to 25 July, 1997   \n",
       "6                     25 July, 1987 to 25 July, 1992   \n",
       "7                     25 July, 1982 to 25 July, 1987   \n",
       "8                     25 July, 1977 to 25 July, 1982   \n",
       "9                24 August, 1974 to 11 February, 1977  \n",
       "10   3 May, 1969 to 20 July, 1969 and 24 August, 1...  \n",
       "11                        13 May, 1967 to 3 May, 1969  \n",
       "12                       13 May, 1962 to 13 May, 1967  \n",
       "13                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Sending request to the url\n",
    "re = requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "\n",
    "# Getting page contents\n",
    "bs = BeautifulSoup(re.content)\n",
    "\n",
    "# Making two different empty lists to add names and terms of office in it\n",
    "name = []\n",
    "tof = []\n",
    "for i in bs.find_all('div',class_='presidentListing'): # Finding the data from the page\n",
    "    n = i.text.split('\\n')[1]  # Getting required data and holding it in a variable by splitting it\n",
    "    name.append(n.split('(')[0])  # Appending only required data i.e name in list by splitting it again\n",
    "    \n",
    "    t = i.text.split(':')[1]  # Getting required data i.e terms of office by splitting it\n",
    "    tof.append(t.split('\\n')[0])  # Getting only dates by again splitting unnecessary data from it\n",
    "    \n",
    "# Making dataframe\n",
    "df = pd.DataFrame({'Former Presidents Name':name,'Terms of Office':tof})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab62db4",
   "metadata": {},
   "source": [
    "# 5. Top 10 ODI Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a850db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>23</td>\n",
       "      <td>2,670</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>30</td>\n",
       "      <td>3,400</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>32</td>\n",
       "      <td>3,572</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>35</td>\n",
       "      <td>3,866</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>22</td>\n",
       "      <td>2,354</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>2,392</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>30</td>\n",
       "      <td>2,753</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>30</td>\n",
       "      <td>2,677</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>19</td>\n",
       "      <td>1,380</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>41</td>\n",
       "      <td>2,902</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Teams Matches Points Rating\n",
       "0   New Zealand      23  2,670    116\n",
       "1       England      30  3,400    113\n",
       "2     Australia      32  3,572    112\n",
       "3         India      35  3,866    110\n",
       "4      Pakistan      22  2,354    107\n",
       "5  South Africa      24  2,392    100\n",
       "6    Bangladesh      30  2,753     92\n",
       "7     Sri Lanka      30  2,677     89\n",
       "8   Afghanistan      19  1,380     73\n",
       "9   West Indies      41  2,902     71"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Sending request to the page for source code\n",
    "rq = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi') \n",
    "\n",
    "# Getting the contents of page\n",
    "bs = BeautifulSoup(rq.content)\n",
    "\n",
    "# Making a user defined function for this\n",
    "def Top_10():\n",
    "    tm = [] # Creating enmpty table to insert teams\n",
    "    for i in bs.find_all('span',class_='u-hide-phablet'):\n",
    "        tm.append(i.text)\n",
    "    teams = tm[:10]    # Getting only top 10 teams\n",
    "    \n",
    "    # Matches for teams\n",
    "    mt = [] # Empty list to add no of matches in it\n",
    "    m = bs.find('td',class_='rankings-block__banner--matches')  # Getting the top team matches\n",
    "    mt.append(m.text)                                           # Appending the top team matches\n",
    "    p = bs.find('td',class_='rankings-block__banner--points')  # Getting the top team points\n",
    "    mt.append(p.text)                                          # Appending the top team matches\n",
    "    \n",
    "    for i in bs.find_all('td',class_='table-body__cell u-center-text'): # Getting rest teams matches and points respectively\n",
    "        mt.append(i.text)\n",
    "        \n",
    "    matches = mt[0:19:2]  # Getting the top 10 teams matches only\n",
    "    \n",
    "    # Points of top 10 teams\n",
    "    points = mt[1:21:2]\n",
    "    \n",
    "    # Ratings of teams\n",
    "    rt = []  # Making empty list to get ratings of all teams\n",
    "    r = bs.find('td',class_='rankings-block__banner--rating u-text-right') # Getting the top team rating\n",
    "    tr = r.text.split() # Getting only required data\n",
    "    rt.append(tr[0])    # Appending the top team rating\n",
    "    \n",
    "    for i in bs.find_all('td',class_='table-body__cell u-text-right rating'): # Getting all teams ratings respectively\n",
    "        rt.append(i.text)  # Appending the ratings in list\n",
    "        \n",
    "    rating = rt[:10]  # Getting only top 10 team ratings\n",
    "    \n",
    "    # Framing the data in structured form\n",
    "    df = pd.DataFrame({'Teams':teams,'Matches':matches,'Points':points,'Rating':rating})\n",
    "    return df\n",
    "    \n",
    "Top_10()\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8294448",
   "metadata": {},
   "source": [
    "Top 10 ODI Batsmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b67c950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>[PAK]</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Imam-ul-Haq]</td>\n",
       "      <td>[PAK]</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Rassie, van, der, Dussen]</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Quinton, de, Kock]</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[David, Warner]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Steve, Smith]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Jonny, Bairstow]</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Virat, Kohli]</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Rohit, Sharma]</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Kane, Williamson]</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Player   Team Rating\n",
       "0                  Babar Azam  [PAK]    890\n",
       "1               [Imam-ul-Haq]  [PAK]    779\n",
       "2  [Rassie, van, der, Dussen]   [SA]    766\n",
       "3         [Quinton, de, Kock]   [SA]    759\n",
       "4             [David, Warner]  [AUS]    747\n",
       "5              [Steve, Smith]  [AUS]    719\n",
       "6           [Jonny, Bairstow]  [ENG]    710\n",
       "7              [Virat, Kohli]  [IND]    707\n",
       "8             [Rohit, Sharma]  [IND]    704\n",
       "9          [Kane, Williamson]   [NZ]    701"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "from bs4 import BeautifulSoup # This will help to get content\n",
    "import requests  # this will send request to the server for source code\n",
    "import pandas as pd  # this will help to make dataframe\n",
    "\n",
    "# Sending request to the url\n",
    "re = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "\n",
    "# Getting page content\n",
    "bs = BeautifulSoup(re.content)\n",
    "\n",
    "# Making user defined function for this\n",
    "def Batsmen():\n",
    "    # Making list to add top batsmen in list\n",
    "    n = []\n",
    "    b = bs.find('div',class_='rankings-block__banner--name-large') # Getting top batsman\n",
    "    n.append(b.text) # appending top batsman in the list\n",
    "    for i in bs.find_all('td',class_='table-body__cell rankings-table__name name'): # Getting rest batsmen respectively\n",
    "        n.append(i.text.split()) # appending only required data of rest all batsmen one by one respectively by splitting them\n",
    "    name = n[:10]  # Adding only top ten batsmen in list\n",
    "    \n",
    "    # Making list to add their teams respectively\n",
    "    t = []\n",
    "    te = bs.find('div',class_='rankings-block__banner--nationality') # Getting top batsman team\n",
    "    t.append(te.text.split()) # appending only required data of top batsman in the list by splitting them\n",
    "    for i in bs.find_all('span',class_='table-body__logo-text'): # Getting rest batsmen teams respectively\n",
    "        t.append(i.text.split()) # appending only required data of team to the list\n",
    "    team = t[:10] # adding only top ten batsmen team in list respectively\n",
    "    \n",
    "    # Making list to add their ratings\n",
    "    r = []\n",
    "    rt = bs.find('div',class_='rankings-block__banner--rating') # Getting only first player rating\n",
    "    r.append(rt.text) # appending only top batsmen rating in list\n",
    "    for i in bs.find_all('td',class_='table-body__cell rating'): # Getting rest batsmen ratings respectively\n",
    "        r.append(i.text) # Appending rest batsmen ratings respectively\n",
    "    rating = r[0:10] # Adding only top ten batsmen ratings\n",
    "    \n",
    "    # Making Dataframe\n",
    "    df = pd.DataFrame({'Player':name,'Team':team,'Rating':rating})\n",
    "    \n",
    "    return df\n",
    "\n",
    "Batsmen()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce2b3f52",
   "metadata": {},
   "source": [
    "Top 10 ODI Bowlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bef182dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Josh, Hazlewood]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Mitchell, Starc]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Shaheen, Afridi]</td>\n",
       "      <td>PAK</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Matt, Henry]</td>\n",
       "      <td>NZ</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Adam, Zampa]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Mehedi, Hasan]</td>\n",
       "      <td>BAN</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Mujeeb, Ur, Rahman]</td>\n",
       "      <td>AFG</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Mustafizur, Rahman]</td>\n",
       "      <td>BAN</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Rashid, Khan]</td>\n",
       "      <td>AFG</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Player Name Team Ratings\n",
       "0           Trent Boult   NZ     760\n",
       "1     [Josh, Hazlewood]  AUS     727\n",
       "2     [Mitchell, Starc]  AUS     665\n",
       "3     [Shaheen, Afridi]  PAK     661\n",
       "4         [Matt, Henry]   NZ     656\n",
       "5         [Adam, Zampa]  AUS     655\n",
       "6       [Mehedi, Hasan]  BAN     655\n",
       "7  [Mujeeb, Ur, Rahman]  AFG     650\n",
       "8  [Mustafizur, Rahman]  BAN     640\n",
       "9        [Rashid, Khan]  AFG     635"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Sending request to the url\n",
    "re = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "\n",
    "# Getting content of the page\n",
    "bs = BeautifulSoup(re.content)\n",
    "\n",
    "# Making user defined function for this operation\n",
    "def Bowlers():\n",
    "    # Making empty list to add bowlers name into it\n",
    "    n = []\n",
    "    b = bs.find('div',class_='rankings-block__banner--name-large') # Getting only top bowler name\n",
    "    n.append(b.text)\n",
    "    for i in bs.find_all('td',class_='table-body__cell rankings-table__name name'): # Getting rest players name one by one\n",
    "        n.append(i.text.split()) # Adding rest players name by splitting unnecessary data\n",
    "    name = n[:10]  # Getting only top ten bowlers\n",
    "    \n",
    "    # Making empty list to add players team\n",
    "    t = []\n",
    "    tb = bs.find('div',class_='rankings-block__banner--nationality') # Getting only top player team\n",
    "    b = tb.text.split()  # getting top bowler team name by splitting unnecessary data\n",
    "    t.append(b[0]) # appending only required data \n",
    "    for i in bs.find_all('span',class_='table-body__logo-text'): # Getting rest players team\n",
    "        tn = i.text.split()  # getting only required data in the list by splitting it\n",
    "        t.append(tn[0]) # Appending only required data\n",
    "    team = t[:10] # Getting only top 10 players team name respectively\n",
    "    \n",
    "    # Making list to add ratings into it\n",
    "    r = []\n",
    "    tr = bs.find('div',class_='rankings-block__banner--rating') # Getting only top player rating \n",
    "    r.append(tr.text) # Appending only top player rating into list\n",
    "    for i in bs.find_all('td',class_='table-body__cell rating'): # Getting rest players ratings respectively\n",
    "        r.append(i.text) # appending rest players ratings one by one respectively in list\n",
    "    rating = r[:10]  # Getting only top 10 players ratings\n",
    "    \n",
    "    # Making Dataframe\n",
    "    df = pd.DataFrame({'Player Name':name,'Team':team,'Ratings':rating})\n",
    "    \n",
    "    return df\n",
    "\n",
    "Bowlers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f857a4",
   "metadata": {},
   "source": [
    "# 6. Top 10 Womens ODI Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03587c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>18</td>\n",
       "      <td>3,061</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>25</td>\n",
       "      <td>2,904</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>27</td>\n",
       "      <td>2,820</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>24</td>\n",
       "      <td>2,425</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>24</td>\n",
       "      <td>2,334</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>12</td>\n",
       "      <td>932</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>8</td>\n",
       "      <td>572</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>24</td>\n",
       "      <td>1,519</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>8</td>\n",
       "      <td>353</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Teams Matches Points Rating\n",
       "0     Australia      18  3,061    170\n",
       "1  South Africa      26  3,098    119\n",
       "2       England      25  2,904    116\n",
       "3         India      27  2,820    104\n",
       "4   New Zealand      24  2,425    101\n",
       "5   West Indies      24  2,334     97\n",
       "6    Bangladesh      12    932     78\n",
       "7      Thailand       8    572     72\n",
       "8      Pakistan      24  1,519     63\n",
       "9     Sri Lanka       8    353     44"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Sending request to the page for source code\n",
    "rq = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi') \n",
    "\n",
    "# Getting the contents of page\n",
    "bs = BeautifulSoup(rq.content)\n",
    "\n",
    "# Making a user defined function for this\n",
    "def Top_10_Women():\n",
    "    tm = [] # Creating enmpty table to insert teams\n",
    "    for i in bs.find_all('span',class_='u-hide-phablet'):\n",
    "        tm.append(i.text)\n",
    "    teams = tm[:10]    # Getting only top 10 womens teams\n",
    "    \n",
    "    # Matches for teams\n",
    "    ma = [] # Empty list to add no of matches in it\n",
    "    m = bs.find('td',class_='rankings-block__banner--matches')  # Getting only top womens team matches\n",
    "    ma.append(m.text)                                           # Appending the top team matches\n",
    "    p = bs.find('td',class_='rankings-block__banner--points')  # Getting only top womens team points\n",
    "    ma.append(p.text)                                          # Appending the top team matches\n",
    "    \n",
    "    for i in bs.find_all('td',class_='table-body__cell u-center-text'): # Getting rest teams matches and points respectively\n",
    "        ma.append(i.text)\n",
    "        \n",
    "    matches = ma[0:19:2]  # Getting the top 10 womens teams matches only\n",
    "    \n",
    "    # Points of top 10 womens teams respectively\n",
    "    points = ma[1:21:2]\n",
    "    \n",
    "    # Ratings of teams respectively\n",
    "    rt = []  # Making empty list to get ratings of all teams\n",
    "    r = bs.find('td',class_='rankings-block__banner--rating u-text-right') # Getting only top team rating\n",
    "    tr = r.text.split() # Getting only required data by splitting unnesessary data\n",
    "    rt.append(tr[0])    # Appending only top team rating\n",
    "    \n",
    "    for i in bs.find_all('td',class_='table-body__cell u-text-right rating'): # Getting all teams ratings respectively\n",
    "        rt.append(i.text)  # Appending the ratings in list\n",
    "        \n",
    "    rating = rt[:10]  # Getting only top 10 team ratings\n",
    "    \n",
    "    # Framing the data in structured form\n",
    "    df = pd.DataFrame({'Teams':teams,'Matches':matches,'Points':points,'Rating':rating})\n",
    "    return df\n",
    "    \n",
    "Top_10_Women()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62413a0f",
   "metadata": {},
   "source": [
    "Top 10 Womens ODI batsmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe7c7705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Beth, Mooney]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Laura, Wolvaardt]</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Natalie, Sciver]</td>\n",
       "      <td>ENG</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Harmanpreet, Kaur]</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Smriti, Mandhana]</td>\n",
       "      <td>IND</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Meg, Lanning]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Rachael, Haynes]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Amy, Satterthwaite]</td>\n",
       "      <td>NZ</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Chamari, Athapaththu]</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name Team Rating\n",
       "0            Alyssa Healy  AUS    785\n",
       "1          [Beth, Mooney]  AUS    749\n",
       "2      [Laura, Wolvaardt]   SA    732\n",
       "3       [Natalie, Sciver]  ENG    725\n",
       "4     [Harmanpreet, Kaur]  IND    716\n",
       "5      [Smriti, Mandhana]  IND    714\n",
       "6          [Meg, Lanning]  AUS    710\n",
       "7       [Rachael, Haynes]  AUS    701\n",
       "8    [Amy, Satterthwaite]   NZ    661\n",
       "9  [Chamari, Athapaththu]   SL    655"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Sending requests to get data\n",
    "re = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "\n",
    "# Getting page contents\n",
    "bs = BeautifulSoup(re.content)\n",
    "\n",
    "# Making a user defined function for this operation\n",
    "def Women_Batsmen():\n",
    "    # Making empty list to add top women batsmen in it\n",
    "    w = []\n",
    "    tw = bs.find('div',class_='rankings-block__banner--name-large') # Getting only top women batsman name\n",
    "    w.append(tw.text)\n",
    "    for i in bs.find_all('td',class_='table-body__cell rankings-table__name name'): # Getting rest all women batsmen names\n",
    "        w.append(i.text.split()) # Appending only required data by splitting it\n",
    "    women = w[:10] # Getting only top ten women batsmen name\n",
    "    \n",
    "    # Making empty list to add team name into it\n",
    "    t = []\n",
    "    tt = bs.find('div',class_='rankings-block__banner--nationality') # Getting only top women batsmen team name\n",
    "    l=tt.text.split() # Getting only required data by splitting it and holding it in a new variable\n",
    "    t.append(l[0]) # Appending only required data into the list\n",
    "    for i in bs.find_all('span',class_='table-body__logo-text'): # Getting rest women batsmen team name respectively\n",
    "        t.append(i.text) # Adding only required data by splitting it\n",
    "    team = t[:10]\n",
    "    \n",
    "    # Making empty list to add top Women batsmen rating\n",
    "    r = []\n",
    "    tr = bs.find('div',class_='rankings-block__banner--rating') # gettign only top team rating\n",
    "    r.append(tr.text) # Getting only top women batsmen rating\n",
    "    for i in bs.find_all('td',class_='table-body__cell rating'): # getting rest women batsmen ratings one by one\n",
    "        r.append(i.text) # Appending rest women batsmen ratings one by one respectively\n",
    "    rating = r[:10] # Getting only top ten women batsmen ratings\n",
    "    \n",
    "    # Making Dataframe\n",
    "    df = pd.DataFrame({'Name':women,'Team':team,'Rating':rating})\n",
    "    return df\n",
    "\n",
    "Women_Batsmen()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "285e0f2b",
   "metadata": {},
   "source": [
    "Top 10 women ODI Bowlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e436b545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Ellyse, Perry]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Natalie, Sciver]</td>\n",
       "      <td>ENG</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Amelia, Kerr]</td>\n",
       "      <td>NZ</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Marizanne, Kapp]</td>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Deepti, Sharma]</td>\n",
       "      <td>IND</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Ashleigh, Gardner]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Jess, Jonassen]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Jhulan, Goswami]</td>\n",
       "      <td>IND</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Katherine, Brunt]</td>\n",
       "      <td>ENG</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Player Name Team Rating\n",
       "0      Hayley Matthews   WI    380\n",
       "1      [Ellyse, Perry]  AUS    374\n",
       "2    [Natalie, Sciver]  ENG    357\n",
       "3       [Amelia, Kerr]   NZ    356\n",
       "4    [Marizanne, Kapp]   SA    349\n",
       "5     [Deepti, Sharma]  IND    322\n",
       "6  [Ashleigh, Gardner]  AUS    270\n",
       "7     [Jess, Jonassen]  AUS    246\n",
       "8    [Jhulan, Goswami]  IND    214\n",
       "9   [Katherine, Brunt]  ENG    207"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Sending request to the url\n",
    "re = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "\n",
    "# Getting page contents\n",
    "bs = BeautifulSoup(re.content)\n",
    "\n",
    "# Making a user defined function for this operation\n",
    "def Women_Allrounder():\n",
    "    # Making an empty list to store names of allrounders in it\n",
    "    wa = []\n",
    "    t = bs.find('div',class_='rankings-block__banner--name-large') # Getting only top allrounder name\n",
    "    wa.append(t.text) # Appending only top allrounder in the list\n",
    "    for i in bs.find_all('td',class_='table-body__cell rankings-table__name name'): # Gettting rest names respectively\n",
    "        wa.append(i.text.split()) # Appending only required data by splitting it\n",
    "    name = wa[:10]  # Getting only top ten names\n",
    "    \n",
    "    # Making empty list to add teams of allrounders respectively\n",
    "    te = []\n",
    "    tm = bs.find('div',class_='rankings-block__banner--nationality') # Getting only first player team\n",
    "    te.append(tm.text.split()[0]) # Appending only required data by splitting it\n",
    "    for i in bs.find_all('span',class_='table-body__logo-text'): # Getting rest player's teams respectively\n",
    "        te.append(i.text) # Appending rest players teams name respectively\n",
    "    team = te[:10]  # Getting only top 10 players team name\n",
    "    \n",
    "    # Making an empty list to append players ratings\n",
    "    r = []\n",
    "    rt = bs.find('div',class_='rankings-block__banner--rating') # Getting only top player rating\n",
    "    r.append(rt.text)  # Appending only top player rating\n",
    "    for i in bs.find_all('td',class_='table-body__cell rating'): # Getting rest players ratings\n",
    "        r.append(i.text)  # Appending rest players ratings respectively\n",
    "    rating = r[:10]  # Getting only top 10 players ratings\n",
    "    \n",
    "    # Making Dataframe\n",
    "    df = pd.DataFrame({'Player Name':name,'Team':team,'Rating':rating})\n",
    "    return df\n",
    "\n",
    "Women_Allrounder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f626c8",
   "metadata": {},
   "source": [
    "# 7. News Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6692d648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parking lots are becoming as important as cars...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/parking-lots-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon's cloud unit faces cost-sensitive custo...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/aws-faces-cost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don’t overlook this health warning on your dec...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/dont-overlook-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How electric air taxis could shake up the airl...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/how-electric-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I raised 2 successful CEOs and a doctor. Here'...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/i-raised-2-suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Delta pilots would get more than 30% in pay ra...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/delta-pilots-w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Men participate less in 401(k) plans than wome...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/men-participat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The best U.S. states to raise a family if you ...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/best-states-ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Susan Cain: This Bob Dylan-inspired phrase can...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/bestselling-au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The difference between this comeback and the m...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/the-difference...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Goldman says buy these five stocks for the lon...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/goldman-says-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Celsius users with crypto collateral stuck tur...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/celsius-users-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cramer's lightning round: Let Extreme Networks...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/cramers-lightn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jim Cramer says these 3 apparel stocks benefit...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/jim-cramer-say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cramer’s week ahead: Markets need a strong job...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/cramers-week-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pro Picks: Watch all of Friday's big stock cal...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/pro-picks-watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>There is 'enormous opportunity' in REITs, says...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/reits-offer-en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Biden administration will end monkeypox public...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/biden-administ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Expect more choppiness ahead after a week of m...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/expect-more-ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GM, LG investing $275 million to expand Tennes...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/gm-lg-investin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>These beat-up tech stocks have potential, ‘Hal...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/big-tech-stock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The Fed's path to a 'Goldilocks' economy just ...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/the-feds-path-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3 things crypto investors need to know in post...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/three-things-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Biden condemns antisemitism as Ye praises Hitl...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/biden-condemns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Georgia man arrested for shooting boy campaign...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/georgia-electi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What to watch in the markets in the week ahead</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/markets-lookin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The biggest tax changes to know before filing ...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/the-biggest-ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>'This is a crisis.' Why more workers need acce...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/why-more-worke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Carnival’s Princess Cruises will return to Jap...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/carnivals-prin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Tech layoffs may not be a bad omen for U.S. ec...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/tech-layoffs-m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline              Time  \\\n",
       "0   Parking lots are becoming as important as cars...      19 Hours Ago   \n",
       "1   Amazon's cloud unit faces cost-sensitive custo...      20 Hours Ago   \n",
       "2   Don’t overlook this health warning on your dec...      20 Hours Ago   \n",
       "3   How electric air taxis could shake up the airl...      20 Hours Ago   \n",
       "4   I raised 2 successful CEOs and a doctor. Here'...      20 Hours Ago   \n",
       "5   Delta pilots would get more than 30% in pay ra...      20 Hours Ago   \n",
       "6   Men participate less in 401(k) plans than wome...      21 Hours Ago   \n",
       "7   The best U.S. states to raise a family if you ...      21 Hours Ago   \n",
       "8   Susan Cain: This Bob Dylan-inspired phrase can...      21 Hours Ago   \n",
       "9   The difference between this comeback and the m...      21 Hours Ago   \n",
       "10  Goldman says buy these five stocks for the lon...      21 Hours Ago   \n",
       "11  Celsius users with crypto collateral stuck tur...      22 Hours Ago   \n",
       "12  Cramer's lightning round: Let Extreme Networks...  December 2, 2022   \n",
       "13  Jim Cramer says these 3 apparel stocks benefit...  December 2, 2022   \n",
       "14  Cramer’s week ahead: Markets need a strong job...  December 2, 2022   \n",
       "15  Pro Picks: Watch all of Friday's big stock cal...  December 2, 2022   \n",
       "16  There is 'enormous opportunity' in REITs, says...  December 2, 2022   \n",
       "17  Biden administration will end monkeypox public...  December 2, 2022   \n",
       "18  Expect more choppiness ahead after a week of m...  December 2, 2022   \n",
       "19  GM, LG investing $275 million to expand Tennes...  December 2, 2022   \n",
       "20  These beat-up tech stocks have potential, ‘Hal...  December 2, 2022   \n",
       "21  The Fed's path to a 'Goldilocks' economy just ...  December 2, 2022   \n",
       "22  3 things crypto investors need to know in post...  December 2, 2022   \n",
       "23  Biden condemns antisemitism as Ye praises Hitl...  December 2, 2022   \n",
       "24  Georgia man arrested for shooting boy campaign...  December 2, 2022   \n",
       "25     What to watch in the markets in the week ahead  December 2, 2022   \n",
       "26  The biggest tax changes to know before filing ...  December 2, 2022   \n",
       "27  'This is a crisis.' Why more workers need acce...  December 2, 2022   \n",
       "28  Carnival’s Princess Cruises will return to Jap...  December 2, 2022   \n",
       "29  Tech layoffs may not be a bad omen for U.S. ec...  December 2, 2022   \n",
       "\n",
       "                                            News Link  \n",
       "0   https://www.cnbc.com/2022/12/03/parking-lots-b...  \n",
       "1   https://www.cnbc.com/2022/12/03/aws-faces-cost...  \n",
       "2   https://www.cnbc.com/2022/12/03/dont-overlook-...  \n",
       "3   https://www.cnbc.com/2022/12/03/how-electric-a...  \n",
       "4   https://www.cnbc.com/2022/12/03/i-raised-2-suc...  \n",
       "5   https://www.cnbc.com/2022/12/03/delta-pilots-w...  \n",
       "6   https://www.cnbc.com/2022/12/03/men-participat...  \n",
       "7   https://www.cnbc.com/2022/12/03/best-states-ra...  \n",
       "8   https://www.cnbc.com/2022/12/03/bestselling-au...  \n",
       "9   https://www.cnbc.com/2022/12/03/the-difference...  \n",
       "10  https://www.cnbc.com/2022/12/03/goldman-says-b...  \n",
       "11  https://www.cnbc.com/2022/12/03/celsius-users-...  \n",
       "12  https://www.cnbc.com/2022/12/02/cramers-lightn...  \n",
       "13  https://www.cnbc.com/2022/12/02/jim-cramer-say...  \n",
       "14  https://www.cnbc.com/2022/12/02/cramers-week-a...  \n",
       "15  https://www.cnbc.com/2022/12/02/pro-picks-watc...  \n",
       "16  https://www.cnbc.com/2022/12/02/reits-offer-en...  \n",
       "17  https://www.cnbc.com/2022/12/02/biden-administ...  \n",
       "18  https://www.cnbc.com/2022/12/02/expect-more-ch...  \n",
       "19  https://www.cnbc.com/2022/12/02/gm-lg-investin...  \n",
       "20  https://www.cnbc.com/2022/12/02/big-tech-stock...  \n",
       "21  https://www.cnbc.com/2022/12/02/the-feds-path-...  \n",
       "22  https://www.cnbc.com/2022/12/02/three-things-c...  \n",
       "23  https://www.cnbc.com/2022/12/02/biden-condemns...  \n",
       "24  https://www.cnbc.com/2022/12/02/georgia-electi...  \n",
       "25  https://www.cnbc.com/2022/12/02/markets-lookin...  \n",
       "26  https://www.cnbc.com/2022/12/02/the-biggest-ta...  \n",
       "27  https://www.cnbc.com/2022/12/02/why-more-worke...  \n",
       "28  https://www.cnbc.com/2022/12/02/carnivals-prin...  \n",
       "29  https://www.cnbc.com/2022/12/02/tech-layoffs-m...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Sending request to the url\n",
    "re = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "\n",
    "# Getting page contents\n",
    "bs = BeautifulSoup(re.content)\n",
    "\n",
    "# Making a user defined function for this\n",
    "def News_Details():\n",
    "    \n",
    "    # Making an empty list to store headlines in it\n",
    "    headline = []\n",
    "    for i in bs.find_all('a',class_='LatestNews-headline'): # Getting all headlines\n",
    "        headline.append(i.text) # Appending all headline one by one in list\n",
    "        \n",
    "    # Making an empty list to add time in it\n",
    "    time = []\n",
    "    for i in bs.find_all('time',class_='LatestNews-timestamp'): # Getting relative time of the headlines\n",
    "        time.append(i.text)\n",
    "        \n",
    "    # Making an empty list to store news link\n",
    "    nl = []\n",
    "    for i in bs.find_all('a',class_='LatestNews-headline'): # Getting news link respectively\n",
    "        nl.append(i.get('href'))  # Appending news link in the list\n",
    "        \n",
    "    # Making Dataframe\n",
    "    df = pd.DataFrame({'Headline':headline,'Time':time,'News Link':nl})\n",
    "    \n",
    "    # Returning to get dataframe\n",
    "    return df\n",
    "\n",
    "\n",
    "News_Details()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44b3f0b",
   "metadata": {},
   "source": [
    "# 8. AI Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "820f66db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors  Published Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                            Paper URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Sending request to the url\n",
    "re = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "\n",
    "# Getting page contents\n",
    "bs = BeautifulSoup(re.content)\n",
    "\n",
    "# Making a user defined function to do this operation\n",
    "def AI():\n",
    "    \n",
    "    # Making an empty list to add paper titles in it\n",
    "    pt = []\n",
    "    for i in bs.find_all('h2',class_='sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg'): # Getting paper title\n",
    "        pt.append(i.text)  # Appending paper title in list\n",
    "        \n",
    "    # Making an empty list to add authors name in it\n",
    "    authors = []\n",
    "    for i in bs.find_all('span',class_='sc-1w3fpd7-0 dnCnAO'): # Getting authors name one by one respectively\n",
    "        authors.append(i.text)  # Appending authors name in list one by one\n",
    "    \n",
    "    # Making an empty list to add publised date of article in it respectively\n",
    "    pdate = []\n",
    "    for i in bs.find_all('span',class_='sc-1thf9ly-2 dvggWt'): # Getting published date of the atricles respectively one by one\n",
    "        pdate.append(i.text) # Appending published date in the list\n",
    "        \n",
    "    # Making an empty list to add paper url\n",
    "    url = []\n",
    "    for i in bs.find_all('a',class_='sc-5smygv-0 fIXTHm'): # Getting papers url\n",
    "        url.append(i.get('href'))\n",
    "        \n",
    "    # Making dataframe\n",
    "    df = pd.DataFrame({'Paper Title':pt,'Authors':authors,'Published Date':pdate,'Paper URL':url})\n",
    "\n",
    "    # Returning to get dataframe\n",
    "    return df\n",
    "\n",
    "AI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163031e5",
   "metadata": {},
   "source": [
    "# 9. Restraunt Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dda5478a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Cousine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Restaurant Name                        Cousine  \\\n",
       "0                   Castle Barbeque          Chinese, North Indian   \n",
       "1                   Jungle Jamboree   North Indian, Asian, Italian   \n",
       "2                   Castle Barbeque          Chinese, North Indian   \n",
       "3                        Cafe Knosh           Italian, Continental   \n",
       "4              The Barbeque Company          North Indian, Chinese   \n",
       "5                       India Grill          North Indian, Italian   \n",
       "6                    Delhi Barbeque                   North Indian   \n",
       "7  The Monarch - Bar Be Que Village                   North Indian   \n",
       "8                 Indian Grill Room          North Indian, Mughlai   \n",
       "\n",
       "                                            Location Ratings  \\\n",
       "0                     Connaught Place, Central Delhi     4.1   \n",
       "1             3CS Mall,Lajpat Nagar - 3, South Delhi     3.9   \n",
       "2             Pacific Mall,Tagore Garden, West Delhi     3.9   \n",
       "3  The Leela Ambience Convention Hotel,Shahdara, ...     4.3   \n",
       "4                 Gardens Galleria,Sector 38A, Noida       4   \n",
       "5               Hilton Garden Inn,Saket, South Delhi     3.9   \n",
       "6     Taurus Sarovar Portico,Mahipalpur, South Delhi     3.6   \n",
       "7  Indirapuram Habitat Centre,Indirapuram, Ghaziabad     3.8   \n",
       "8   Suncity Business Tower,Golf Course Road, Gurgaon     4.3   \n",
       "\n",
       "                                           Image URL  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Sending request to url \n",
    "re = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "\n",
    "# Getting page contents\n",
    "bs = BeautifulSoup(re.content)\n",
    "\n",
    "# Making an empty list to add restaurants name into it\n",
    "rname = []\n",
    "for i in bs.find_all('a',class_='restnt-name ellipsis'): # Getting restaurants name one by one\n",
    "    rname.append(i.text)  # Appending restaurants name in the list\n",
    "    \n",
    "# Making an empty list to add cousine in it\n",
    "cousine = []\n",
    "for i in bs.find_all('span',class_='double-line-ellipsis'): # Getting cousine \n",
    "    cousine.append(i.text.split('|')[1]) # Appending only required data in list by splitting it\n",
    "    \n",
    "# Making an empty list to add location of restaurants in it\n",
    "location = []\n",
    "for i in bs.find_all('div',class_='restnt-loc ellipsis'): # Getting location of restaurants one by one respectively\n",
    "    location.append(i.text)  # Appending locations in list one by one\n",
    "    \n",
    "# Making empty list to add ratings in it\n",
    "rating = []\n",
    "for i in bs.find_all('div',class_='restnt-rating rating-4'): # Getting ratings of restaurants respectively\n",
    "    rating.append(i.text) # Appending ratings one by one respectively\n",
    "    \n",
    "# Making an empty list to add image url in it\n",
    "image = []\n",
    "for i in bs.find_all('img',class_='no-img'): # Getting image url\n",
    "    image.append(i.get('data-src')) # Appending image url in list respectively\n",
    "    \n",
    "# Making dataframe\n",
    "df = pd.DataFrame({'Restaurant Name':rname,'Cousine':cousine,'Location':location,'Ratings':rating,'Image URL':image})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637bff96",
   "metadata": {},
   "source": [
    "# 10. Top Google Scholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d88687dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5-index</th>\n",
       "      <th>h5-median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Sensors</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                        Publication h5-index h5-median\n",
       "0     1.                                             Nature      444       667\n",
       "1     2.                The New England Journal of Medicine      432       780\n",
       "2     3.                                            Science      401       614\n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...      389       627\n",
       "4     5.                                         The Lancet      354       635\n",
       "..   ...                                                ...      ...       ...\n",
       "95   96.                       Journal of Business Research      145       233\n",
       "96   97.                                   Molecular Cancer      145       209\n",
       "97   98.                                            Sensors      145       201\n",
       "98   99.                              Nature Climate Change      144       228\n",
       "99  100.                    IEEE Internet of Things Journal      144       212\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# sending request to url\n",
    "re = requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "\n",
    "# Getting page contents\n",
    "bs = BeautifulSoup(re.content)\n",
    "\n",
    "# Making an empty list to add rank in it\n",
    "rank = []\n",
    "for i in bs.find_all('td',class_='gsc_mvt_p'): # Getting ranks of scholar\n",
    "    rank.append(i.text)  # Appending rank in list\n",
    "    \n",
    "# Making empty list to add publication in it\n",
    "publication = []\n",
    "for i in bs.find_all('td',class_='gsc_mvt_t'):  # Getting publication name one by one\n",
    "    publication.append(i.text)  # Appending publication name in list one by one\n",
    "    \n",
    "# Making empty list to add h5-index and h5-median in it\n",
    "im = []\n",
    "for i in bs.find_all('td',class_='gsc_mvt_n'):  # Getting h5-index and h5-median one by one\n",
    "    im.append(i.text)  # Appending h5-index and h5-median one by one in list respectively\n",
    "    \n",
    "# Getting only h5-index\n",
    "h5index = im[0:200:2]\n",
    "\n",
    "# Getting only h5-median\n",
    "h5median = im[1:200:2]\n",
    "    \n",
    "# Making dataframe\n",
    "df = pd.DataFrame({'Rank':rank,'Publication':publication,'h5-index':h5index,'h5-median':h5median})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f163730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab9e298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca49f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
